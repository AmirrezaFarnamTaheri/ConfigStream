name: ConfigStream Pipeline

on:
  push:
    branches: [main]
  pull_request:
  schedule:
    - cron: "0 */4 * * *"
  workflow_dispatch:

permissions:
  contents: write

jobs:
  lint:
    name: Lint and Static Analysis
    runs-on: ubuntu-latest
    continue-on-error: false
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: pip
          cache-dependency-path: pyproject.toml

      - name: Install dependencies
        run: pip install -e .[dev]

      - name: Run Linters
        run: |
          black --check .
          flake8 .
          mypy .

  test:
    name: Run Test Suite
    runs-on: ubuntu-latest
    continue-on-error: false
    env:
      PYTHONPATH: src
      MAXMIND_LICENSE_KEY: ${{ secrets.MAXMIND_LICENSE_KEY }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: pip
          cache-dependency-path: pyproject.toml

      - name: Install dependencies
        run: pip install -e .[dev]

      - name: Cache sing-box binary
        id: cache-sing-box
        uses: actions/cache@v3
        with:
          path: /usr/local/bin/sing-box
          key: sing-box-linux-amd64-${{ github.sha }}
          restore-keys: |
            sing-box-linux-amd64-

      - name: Install sing-box
        if: steps.cache-sing-box.outputs.cache-hit != 'true'
        run: |
          LATEST_URL=$(curl -s "https://api.github.com/repos/SagerNet/sing-box/releases/latest" | grep "browser_download_url.*linux-amd64" | cut -d '"' -f 4)
          curl -L -o sing-box.tar.gz $LATEST_URL
          tar -xzf sing-box.tar.gz
          # The extracted directory name can vary, so we find it dynamically
          EXTRACTED_DIR=$(tar -tzf sing-box.tar.gz | head -1 | cut -f1 -d"/")
          mv $EXTRACTED_DIR/sing-box /usr/local/bin/
          rm -rf sing-box.tar.gz $EXTRACTED_DIR

      - name: Run tests
        run: python -m pytest --cov=src/configstream --cov-report=term-missing

  pipeline:
    name: Run Batch Shard (${{ matrix.batch_number }})
    runs-on: ubuntu-latest
    needs: [lint, test]
    # Skip pipeline execution on pull requests due to network restrictions in CI
    # Pipeline jobs require fetching from external sources which fail with SSL errors in PR environment
    if: github.event_name != 'pull_request'
    strategy:
      matrix:
        batch_number: [1, 2, 3, 4, 5, 6]
      fail-fast: false # Allow other shards to continue if one fails

    env:
      PYTHONPATH: src
      BATCH_NUMBER: ${{ matrix.batch_number }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: pip
          cache-dependency-path: pyproject.toml

      - name: Restore test cache and GeoIP database
        uses: actions/cache@v3
        with:
          path: |
            data/test_cache.db
            data/GeoLite2-City.mmdb
            output/.etag-cache.json
          key: configstream-cache-${{ github.run_number }}
          restore-keys: |
            configstream-cache-

      - name: Install dependencies
        run: pip install -e .[dev]

      - name: Cache sing-box binary
        id: cache-sing-box
        uses: actions/cache@v3
        with:
          path: /usr/local/bin/sing-box
          key: sing-box-linux-amd64-${{ github.sha }}
          restore-keys: |
            sing-box-linux-amd64-

      - name: Install sing-box
        if: steps.cache-sing-box.outputs.cache-hit != 'true'
        run: |
          LATEST_URL=$(curl -s "https://api.github.com/repos/SagerNet/sing-box/releases/latest" | grep "browser_download_url.*linux-amd64" | cut -d '"' -f 4)
          curl -L -o sing-box.tar.gz $LATEST_URL
          tar -xzf sing-box.tar.gz
          EXTRACTED_DIR=$(tar -tzf sing-box.tar.gz | head -1 | cut -f1 -d"/")
          mv $EXTRACTED_DIR/sing-box /usr/local/bin/
          rm -rf sing-box.tar.gz $EXTRACTED_DIR

      - name: Download GeoIP databases
        env:
          MAXMIND_LICENSE_KEY: ${{ secrets.MAXMIND_LICENSE_KEY }}
        run: python -m configstream.cli update-databases

      - name: Run pipeline for Batch ${{ env.BATCH_NUMBER }}
        run: |
          set -euxo pipefail
          echo "Running pipeline for batch $BATCH_NUMBER"
          python -m configstream.cli merge \
            --sources "sources/batch_${BATCH_NUMBER}.txt" \
            --output "output_batch_${BATCH_NUMBER}" \
            --max-workers 32 \
            --timeout 24 \
            --show-metrics \
            --max-latency 6000 | tee "pipeline_batch_${BATCH_NUMBER}.log"

      - name: Upload shard artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: shard-run-${{ github.sha }}-${{ env.BATCH_NUMBER }}
          path: |
            output_batch_${{ env.BATCH_NUMBER }}/
            pipeline_batch_${{ env.BATCH_NUMBER }}.log

  merge_results:
    name: Merge and Commit Shard Results
    runs-on: ubuntu-latest
    needs: pipeline
    # Skip on pull requests (pipeline job already skipped)
    # Always run on other events to capture logs and partial results
    if: always() && github.event_name != 'pull_request'

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Download shard artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: shard-run-${{ github.sha }}-*
          path: artifacts
          merge-multiple: true

      - name: Restore previous outputs for merge
        run: |
          set -euxo pipefail
          # Check if any artifacts were downloaded
          if [ -z "$(ls -A artifacts)" ]; then
            echo "No artifacts found to restore."
            exit 0
          fi
          # The structure will be artifacts/output_batch_N/...
          # We need to move them to the correct locations.
          find artifacts -mindepth 1 -maxdepth 1 -type d -name 'output_batch_*' -exec mv {} . \;
          find artifacts -type f -name '*.log' -exec mv {} . \;


      - name: Run merge script
        run: python -m scripts.merge_batches

      - name: Show diff
        run: |
          git status --short
          git diff --stat || true

      - name: Commit updated output
        if: github.event_name != 'pull_request' && github.ref == 'refs/heads/main'
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore(data): update outputs from all batches"
          file_pattern: "output/"
          push_options: '--force'
          add_options: '-f'

      - name: Upload final pipeline artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-run-${{ github.sha }}
          path: |
            output/
            output_batch_*/
            *.log
